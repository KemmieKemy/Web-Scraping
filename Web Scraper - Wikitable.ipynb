{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Wikitable\n",
    "1.\tFind the URL that contains that the data you want to extract. \n",
    "2.\tCheck the “robots.txt” of the website.\n",
    "3.\tInstall and Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\tSend a GET request to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research'\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\tParse the html data using Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'List of datasets for machine-learning research - Wikipedia'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "soup.title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\tWrite the code to extract the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Brief description</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Format</th>\n",
       "      <th>Default task</th>\n",
       "      <th>Created (updated)</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Creator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FERET (facial recognition technology)</td>\n",
       "      <td>11338 images of 1199 individuals in different ...</td>\n",
       "      <td>None.</td>\n",
       "      <td>11,338</td>\n",
       "      <td>Images</td>\n",
       "      <td>Classification, face recognition</td>\n",
       "      <td>2003</td>\n",
       "      <td>[6][7]</td>\n",
       "      <td>United States Department of Defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ryerson Audio-Visual Database of Emotional Spe...</td>\n",
       "      <td>7,356 video and audio recordings of 24 profess...</td>\n",
       "      <td>Files labelled with expression. Perceptual val...</td>\n",
       "      <td>7,356</td>\n",
       "      <td>Video, sound files</td>\n",
       "      <td>Classification, face recognition, voice recogn...</td>\n",
       "      <td>2018</td>\n",
       "      <td>[8][9]</td>\n",
       "      <td>S.R. Livingstone and F.A. Russo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCFace</td>\n",
       "      <td>Color images of faces at various angles.</td>\n",
       "      <td>Location of facial features extracted. Coordin...</td>\n",
       "      <td>4,160</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Classification, face recognition</td>\n",
       "      <td>2011</td>\n",
       "      <td>[10][11]</td>\n",
       "      <td>M. Grgic et al.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yale Face Database</td>\n",
       "      <td>Faces of 15 individuals in 11 different expres...</td>\n",
       "      <td>Labels of expressions.</td>\n",
       "      <td>165</td>\n",
       "      <td>Images</td>\n",
       "      <td>Face recognition</td>\n",
       "      <td>1997</td>\n",
       "      <td>[12][13]</td>\n",
       "      <td>J. Yang et al.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Dataset name  \\\n",
       "0                                               None   \n",
       "1              FERET (facial recognition technology)   \n",
       "2  Ryerson Audio-Visual Database of Emotional Spe...   \n",
       "3                                             SCFace   \n",
       "4                                 Yale Face Database   \n",
       "\n",
       "                                   Brief description  \\\n",
       "0                                               None   \n",
       "1  11338 images of 1199 individuals in different ...   \n",
       "2  7,356 video and audio recordings of 24 profess...   \n",
       "3           Color images of faces at various angles.   \n",
       "4  Faces of 15 individuals in 11 different expres...   \n",
       "\n",
       "                                       Preprocessing Instances  \\\n",
       "0                                               None      None   \n",
       "1                                              None.    11,338   \n",
       "2  Files labelled with expression. Perceptual val...     7,356   \n",
       "3  Location of facial features extracted. Coordin...     4,160   \n",
       "4                             Labels of expressions.       165   \n",
       "\n",
       "               Format                                       Default task  \\\n",
       "0                None                                               None   \n",
       "1              Images                   Classification, face recognition   \n",
       "2  Video, sound files  Classification, face recognition, voice recogn...   \n",
       "3        Images, text                   Classification, face recognition   \n",
       "4              Images                                   Face recognition   \n",
       "\n",
       "  Created (updated) Reference                              Creator  \n",
       "0              None      None                                 None  \n",
       "1              2003    [6][7]  United States Department of Defense  \n",
       "2              2018    [8][9]      S.R. Livingstone and F.A. Russo  \n",
       "3              2011  [10][11]                      M. Grgic et al.  \n",
       "4              1997  [12][13]                       J. Yang et al.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = soup.find('table', class_= 'sortable')\n",
    "tr = table.find_all('tr')\n",
    "headers= [header.text.strip('\\n') for header in table.find_all('th')]\n",
    "rows = [] #an empty list to store data\n",
    "for row in table.find_all('tr'):\n",
    "    rows.append([col.text.strip('\\n') for col in row.find_all('td')])\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Brief description</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Format</th>\n",
       "      <th>Default task</th>\n",
       "      <th>Created (updated)</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Creator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FERET (facial recognition technology)</td>\n",
       "      <td>11338 images of 1199 individuals in different ...</td>\n",
       "      <td>None.</td>\n",
       "      <td>11,338</td>\n",
       "      <td>Images</td>\n",
       "      <td>Classification, face recognition</td>\n",
       "      <td>2003</td>\n",
       "      <td>[6][7]</td>\n",
       "      <td>United States Department of Defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ryerson Audio-Visual Database of Emotional Spe...</td>\n",
       "      <td>7,356 video and audio recordings of 24 profess...</td>\n",
       "      <td>Files labelled with expression. Perceptual val...</td>\n",
       "      <td>7,356</td>\n",
       "      <td>Video, sound files</td>\n",
       "      <td>Classification, face recognition, voice recogn...</td>\n",
       "      <td>2018</td>\n",
       "      <td>[8][9]</td>\n",
       "      <td>S.R. Livingstone and F.A. Russo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCFace</td>\n",
       "      <td>Color images of faces at various angles.</td>\n",
       "      <td>Location of facial features extracted. Coordin...</td>\n",
       "      <td>4,160</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Classification, face recognition</td>\n",
       "      <td>2011</td>\n",
       "      <td>[10][11]</td>\n",
       "      <td>M. Grgic et al.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yale Face Database</td>\n",
       "      <td>Faces of 15 individuals in 11 different expres...</td>\n",
       "      <td>Labels of expressions.</td>\n",
       "      <td>165</td>\n",
       "      <td>Images</td>\n",
       "      <td>Face recognition</td>\n",
       "      <td>1997</td>\n",
       "      <td>[12][13]</td>\n",
       "      <td>J. Yang et al.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cohn-Kanade AU-Coded Expression Database</td>\n",
       "      <td>Large database of images with labels for expre...</td>\n",
       "      <td>Tracking of certain facial features.</td>\n",
       "      <td>500+ sequences</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Facial expression analysis</td>\n",
       "      <td>2000</td>\n",
       "      <td>[14][15]</td>\n",
       "      <td>T. Kanade et al.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JAFFE Facial Expression Database</td>\n",
       "      <td>213 images of 7 facial expressions (6 basic fa...</td>\n",
       "      <td>Images are cropped to the facial region. Inclu...</td>\n",
       "      <td>213</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Facial expression cognition</td>\n",
       "      <td>1998</td>\n",
       "      <td>[16][17]</td>\n",
       "      <td>Lyons, Kamachi, Gyoba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FaceScrub</td>\n",
       "      <td>Images of public figures scrubbed from image s...</td>\n",
       "      <td>Name and m/f annotation.</td>\n",
       "      <td>107,818</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Face recognition</td>\n",
       "      <td>2014</td>\n",
       "      <td>[18][19]</td>\n",
       "      <td>H. Ng et al.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BioID Face Database</td>\n",
       "      <td>Images of faces with eye positions marked.</td>\n",
       "      <td>Manually set eye positions.</td>\n",
       "      <td>1521</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Face recognition</td>\n",
       "      <td>2001</td>\n",
       "      <td>[20][21]</td>\n",
       "      <td>BioID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Skin Segmentation Dataset</td>\n",
       "      <td>Randomly sampled color values from face images.</td>\n",
       "      <td>B, G, R, values extracted.</td>\n",
       "      <td>245,057</td>\n",
       "      <td>Text</td>\n",
       "      <td>Segmentation, classification</td>\n",
       "      <td>2012</td>\n",
       "      <td>[22][23]</td>\n",
       "      <td>R. Bhatt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bosphorus</td>\n",
       "      <td>3D Face image database.</td>\n",
       "      <td>34 action units and 6 expressions labeled; 24 ...</td>\n",
       "      <td>4652</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Face recognition, classification</td>\n",
       "      <td>2008</td>\n",
       "      <td>[24][25]</td>\n",
       "      <td>A Savran et al.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UOY 3D-Face</td>\n",
       "      <td>neutral face, 5 expressions: anger, happiness,...</td>\n",
       "      <td>labeling.</td>\n",
       "      <td>5250</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Face recognition, classification</td>\n",
       "      <td>2004</td>\n",
       "      <td>[26][27]</td>\n",
       "      <td>University of York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CASIA 3D Face Database</td>\n",
       "      <td>Expressions: Anger, smile, laugh, surprise, cl...</td>\n",
       "      <td>None.</td>\n",
       "      <td>4624</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Face recognition, classification</td>\n",
       "      <td>2007</td>\n",
       "      <td>[28][29]</td>\n",
       "      <td>Institute of Automation, Chinese Academy of Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CASIA NIR</td>\n",
       "      <td>Expressions: Anger Disgust Fear Happiness Sadn...</td>\n",
       "      <td>None.</td>\n",
       "      <td>480</td>\n",
       "      <td>Annotated Visible Spectrum and Near Infrared V...</td>\n",
       "      <td>Face recognition, classification</td>\n",
       "      <td>2011</td>\n",
       "      <td>[30]</td>\n",
       "      <td>Zhao, G. et al.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BU-3DFE</td>\n",
       "      <td>neutral face, and 6 expressions: anger, happin...</td>\n",
       "      <td>None.</td>\n",
       "      <td>2500</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Facial expression recognition, classification</td>\n",
       "      <td>2006</td>\n",
       "      <td>[31]</td>\n",
       "      <td>Binghamton University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Face Recognition Grand Challenge Dataset</td>\n",
       "      <td>Up to 22 samples for each subject. Expressions...</td>\n",
       "      <td>None.</td>\n",
       "      <td>4007</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Face recognition, classification</td>\n",
       "      <td>2004</td>\n",
       "      <td>[32][33]</td>\n",
       "      <td>National Institute of Standards and Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gavabdb</td>\n",
       "      <td>Up to 61 samples for each subject. Expressions...</td>\n",
       "      <td>None.</td>\n",
       "      <td>549</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Face recognition, classification</td>\n",
       "      <td>2008</td>\n",
       "      <td>[34][35]</td>\n",
       "      <td>King Juan Carlos University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3D-RMA</td>\n",
       "      <td>Up to 100 subjects, expressions mostly neutral...</td>\n",
       "      <td>None.</td>\n",
       "      <td>9971</td>\n",
       "      <td>Images, text</td>\n",
       "      <td>Face recognition, classification</td>\n",
       "      <td>2004</td>\n",
       "      <td>[36][37]</td>\n",
       "      <td>Royal Military Academy (Belgium)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SoF</td>\n",
       "      <td>112 persons (66 males and 46 females) wear gla...</td>\n",
       "      <td>A set of synthetic filters (blur, occlusions, ...</td>\n",
       "      <td>42,592 (2,662 original image × 16 synthetic im...</td>\n",
       "      <td>Images, Mat file</td>\n",
       "      <td>Gender classification, face detection, face re...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[38][39]</td>\n",
       "      <td>Afifi, M. et al.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IMDB-WIKI</td>\n",
       "      <td>IMDB and Wikipedia face images with gender and...</td>\n",
       "      <td>None</td>\n",
       "      <td>523,051</td>\n",
       "      <td>Images</td>\n",
       "      <td>Gender classification, face detection, face re...</td>\n",
       "      <td>2015</td>\n",
       "      <td>[40]</td>\n",
       "      <td>R. Rothe, R. Timofte, L. V. Gool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Dataset name  \\\n",
       "1               FERET (facial recognition technology)   \n",
       "2   Ryerson Audio-Visual Database of Emotional Spe...   \n",
       "3                                              SCFace   \n",
       "4                                  Yale Face Database   \n",
       "5            Cohn-Kanade AU-Coded Expression Database   \n",
       "6                    JAFFE Facial Expression Database   \n",
       "7                                           FaceScrub   \n",
       "8                                 BioID Face Database   \n",
       "9                           Skin Segmentation Dataset   \n",
       "10                                          Bosphorus   \n",
       "11                                        UOY 3D-Face   \n",
       "12                             CASIA 3D Face Database   \n",
       "13                                          CASIA NIR   \n",
       "14                                            BU-3DFE   \n",
       "15           Face Recognition Grand Challenge Dataset   \n",
       "16                                            Gavabdb   \n",
       "17                                             3D-RMA   \n",
       "18                                                SoF   \n",
       "19                                          IMDB-WIKI   \n",
       "\n",
       "                                    Brief description  \\\n",
       "1   11338 images of 1199 individuals in different ...   \n",
       "2   7,356 video and audio recordings of 24 profess...   \n",
       "3            Color images of faces at various angles.   \n",
       "4   Faces of 15 individuals in 11 different expres...   \n",
       "5   Large database of images with labels for expre...   \n",
       "6   213 images of 7 facial expressions (6 basic fa...   \n",
       "7   Images of public figures scrubbed from image s...   \n",
       "8          Images of faces with eye positions marked.   \n",
       "9     Randomly sampled color values from face images.   \n",
       "10                            3D Face image database.   \n",
       "11  neutral face, 5 expressions: anger, happiness,...   \n",
       "12  Expressions: Anger, smile, laugh, surprise, cl...   \n",
       "13  Expressions: Anger Disgust Fear Happiness Sadn...   \n",
       "14  neutral face, and 6 expressions: anger, happin...   \n",
       "15  Up to 22 samples for each subject. Expressions...   \n",
       "16  Up to 61 samples for each subject. Expressions...   \n",
       "17  Up to 100 subjects, expressions mostly neutral...   \n",
       "18  112 persons (66 males and 46 females) wear gla...   \n",
       "19  IMDB and Wikipedia face images with gender and...   \n",
       "\n",
       "                                        Preprocessing  \\\n",
       "1                                               None.   \n",
       "2   Files labelled with expression. Perceptual val...   \n",
       "3   Location of facial features extracted. Coordin...   \n",
       "4                              Labels of expressions.   \n",
       "5                Tracking of certain facial features.   \n",
       "6   Images are cropped to the facial region. Inclu...   \n",
       "7                            Name and m/f annotation.   \n",
       "8                         Manually set eye positions.   \n",
       "9                          B, G, R, values extracted.   \n",
       "10  34 action units and 6 expressions labeled; 24 ...   \n",
       "11                                          labeling.   \n",
       "12                                              None.   \n",
       "13                                              None.   \n",
       "14                                              None.   \n",
       "15                                              None.   \n",
       "16                                              None.   \n",
       "17                                              None.   \n",
       "18  A set of synthetic filters (blur, occlusions, ...   \n",
       "19                                               None   \n",
       "\n",
       "                                            Instances  \\\n",
       "1                                              11,338   \n",
       "2                                               7,356   \n",
       "3                                               4,160   \n",
       "4                                                 165   \n",
       "5                                      500+ sequences   \n",
       "6                                                 213   \n",
       "7                                             107,818   \n",
       "8                                                1521   \n",
       "9                                             245,057   \n",
       "10                                               4652   \n",
       "11                                               5250   \n",
       "12                                               4624   \n",
       "13                                                480   \n",
       "14                                               2500   \n",
       "15                                               4007   \n",
       "16                                                549   \n",
       "17                                               9971   \n",
       "18  42,592 (2,662 original image × 16 synthetic im...   \n",
       "19                                            523,051   \n",
       "\n",
       "                                               Format  \\\n",
       "1                                              Images   \n",
       "2                                  Video, sound files   \n",
       "3                                        Images, text   \n",
       "4                                              Images   \n",
       "5                                        Images, text   \n",
       "6                                        Images, text   \n",
       "7                                        Images, text   \n",
       "8                                        Images, text   \n",
       "9                                                Text   \n",
       "10                                       Images, text   \n",
       "11                                       Images, text   \n",
       "12                                       Images, text   \n",
       "13  Annotated Visible Spectrum and Near Infrared V...   \n",
       "14                                       Images, text   \n",
       "15                                       Images, text   \n",
       "16                                       Images, text   \n",
       "17                                       Images, text   \n",
       "18                                   Images, Mat file   \n",
       "19                                             Images   \n",
       "\n",
       "                                         Default task Created (updated)  \\\n",
       "1                    Classification, face recognition              2003   \n",
       "2   Classification, face recognition, voice recogn...              2018   \n",
       "3                    Classification, face recognition              2011   \n",
       "4                                    Face recognition              1997   \n",
       "5                          Facial expression analysis              2000   \n",
       "6                         Facial expression cognition              1998   \n",
       "7                                    Face recognition              2014   \n",
       "8                                    Face recognition              2001   \n",
       "9                        Segmentation, classification              2012   \n",
       "10                   Face recognition, classification              2008   \n",
       "11                   Face recognition, classification              2004   \n",
       "12                   Face recognition, classification              2007   \n",
       "13                   Face recognition, classification              2011   \n",
       "14      Facial expression recognition, classification              2006   \n",
       "15                   Face recognition, classification              2004   \n",
       "16                   Face recognition, classification              2008   \n",
       "17                   Face recognition, classification              2004   \n",
       "18  Gender classification, face detection, face re...              2017   \n",
       "19  Gender classification, face detection, face re...              2015   \n",
       "\n",
       "   Reference                                            Creator  \n",
       "1     [6][7]                United States Department of Defense  \n",
       "2     [8][9]                    S.R. Livingstone and F.A. Russo  \n",
       "3   [10][11]                                    M. Grgic et al.  \n",
       "4   [12][13]                                     J. Yang et al.  \n",
       "5   [14][15]                                   T. Kanade et al.  \n",
       "6   [16][17]                              Lyons, Kamachi, Gyoba  \n",
       "7   [18][19]                                       H. Ng et al.  \n",
       "8   [20][21]                                              BioID  \n",
       "9   [22][23]                                          R. Bhatt.  \n",
       "10  [24][25]                                    A Savran et al.  \n",
       "11  [26][27]                                 University of York  \n",
       "12  [28][29]  Institute of Automation, Chinese Academy of Sc...  \n",
       "13      [30]                                    Zhao, G. et al.  \n",
       "14      [31]                              Binghamton University  \n",
       "15  [32][33]     National Institute of Standards and Technology  \n",
       "16  [34][35]                        King Juan Carlos University  \n",
       "17  [36][37]                   Royal Military Academy (Belgium)  \n",
       "18  [38][39]                                   Afifi, M. et al.  \n",
       "19      [40]                   R. Rothe, R. Timofte, L. V. Gool  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning the data\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.\tStore the data in a certain format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Wikitable.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
